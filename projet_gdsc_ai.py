# -*- coding: utf-8 -*-
"""Projet GDSC AI

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QMCvKJZ5IrUkfbugILL5RKIqOIu1rddX
"""

!pip install tensorflow opencv-python opencv-python-headless

import cv2
import numpy as np
import tensorflow as tf
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

!pip install --upgrade tensorflow

!pip install tf-models-official
!pip install tf-slim

import cv2
import numpy as np
import tensorflow as tf
from IPython.display import display, Javascript
from google.colab.output import eval_js
from base64 import b64decode

import cv2
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')

from google.colab.patches import cv2_imshow

from transformers import DetrImageProcessor, DetrForObjectDetection
import torch
from PIL import Image
import io
from google.colab import files
import numpy as np
from google.colab.patches import cv2_imshow
import cv2

# Charger une image depuis le système de fichiers local
uploaded = files.upload()

# Vérifier si des fichiers ont été téléchargés
if uploaded:
    # Récupérer les données de l'image téléchargée
    image_bytes = next(iter(uploaded.values()))

    # Convertir les données de l'image en une image PIL
    image = Image.open(io.BytesIO(image_bytes))

    # Convertir l'image en mode RVB si elle n'est pas déjà dans ce format
    if image.mode != "RGB":
        image = image.convert("RGB")

    # Initialiser le processeur d'image DETR
    processor = DetrImageProcessor.from_pretrained("facebook/detr-resnet-101", revision="no_timm")

    # Charger le modèle DETR pré-entraîné pour la détection d'objets
    model = DetrForObjectDetection.from_pretrained("facebook/detr-resnet-101", revision="no_timm")

    # Prétraiter l'image et la convertir en tenseur
    inputs = processor(images=image, return_tensors="pt")

    # Effectuer la détection d'objets sur l'image
    outputs = model(**inputs)

    # Convertir les sorties (boîtes englobantes et logits de classe) en format COCO
    # Ne conserver que les détections avec un score > 0.9
    target_sizes = torch.tensor([image.size[::-1]])
    results = processor.post_process_object_detection(outputs, target_sizes=target_sizes, threshold=0.9)[0]

    # Convertir l'image PIL en tableau NumPy
    image_np = np.array(image)

    # Dessiner les boîtes englobantes des détections sur l'image
    for score, label, box in zip(results["scores"], results["labels"], results["boxes"]):
        box = [int(i) for i in box.tolist()]
        cv2.rectangle(image_np, (box[0], box[1]), (box[2], box[3]), (0, 255, 0), 2)
        cv2.putText(image_np, f"{model.config.id2label[label.item()]}: {score:.2f}", (box[0], box[1] - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)


    cv2_imshow(image_np)
else:
    print("Aucun fichier téléchargé.")